{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weekly activity 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the code chunk found under section Divide an image into smaller patches using cropping into a function with the following signature:\n",
    "crop_grid(img, num_horizontal_grid, num_vertical_grid, line_color)\n",
    " img is the source image\n",
    " num_horizontal_grid and num_vertical_grid are the number of patches along x and y axes.\n",
    " line_color is the color of the grid line.\n",
    " The output of the function should be image with grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('dog.jfif')\n",
    "img_copy = img.copy()\n",
    "\n",
    "def crop_grid(img,num_horizontal_grid,num_vertical_grid,line_color):\n",
    "    \n",
    "    height, width = img.shape[:2]\n",
    "    # M and N are basically number of pixels per patch\n",
    "    M, N = int(height/num_horizontal_grid), int(width/num_vertical_grid)\n",
    "    x1, y1 = 0, 0\n",
    "\n",
    "    for y in range(0, height, M):\n",
    "        for x in range(0, width, N):\n",
    "    #         if (height - y) < M or (width - x) < N:\n",
    "    #             break\n",
    "                \n",
    "            y1 = y + M    # lower right coordinate that will be used to construct rectangle\n",
    "            x1 = x + N\n",
    "            \n",
    "            # Check whether patch lower right coordinate exceeds image height and width\n",
    "            if x1 >= width and y1 >= height:\n",
    "                x1 = width - 1\n",
    "                y1 = height - 1\n",
    "                tile = img[y:height, x:width]\n",
    "                cv.rectangle(img_copy, (x, y), (x1, y1), line_color, 1)\n",
    "                cv.imshow('tile', tile)\n",
    "            # When patch lower right y-coordinate exceeds patch height\n",
    "            elif y1 >= height:\n",
    "                y1 = height - 1\n",
    "                cv.rectangle(img_copy, (x, y), (x1, y1), line_color, 1)\n",
    "                \n",
    "            # When patch lower right x-coordinate exceeds patch width\n",
    "            elif x1 >= width:\n",
    "                x1 = width - 1\n",
    "                cv.rectangle(img_copy, (x, y), (x1, y1), line_color, 1)\n",
    "            \n",
    "            else:\n",
    "                cv.rectangle(img_copy, (x, y), (x1, y1),line_color, 1)\n",
    "\n",
    "    cv.imshow('patched image', img_copy)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "crop_grid(img_copy, 2, 3, (0, 255, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display image sequences of smooth transition of two images with different values of \n",
    "Î±\n",
    ". Refer to code in section \"Image blending\". Use \"lena.jfif\" and \"coins.jfif\" as the base images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.imread('lena.jfif')\n",
    "img2 = cv.imread('coins.jfif')\n",
    "\n",
    "new_shape = img1.shape[:2]\n",
    "img2 = cv.resize(img2, new_shape)\n",
    "skip = False\n",
    "transition = False\n",
    "\n",
    "while True:\n",
    "    for i in np.linspace(0,1,100):\n",
    "\n",
    "        if transition == True:\n",
    "            alpha = i\n",
    "            if i == 1: transition = False\n",
    "        else:\n",
    "            alpha = 1 - i\n",
    "            if i == 1: transition = True\n",
    "\n",
    "        output = cv.addWeighted(img1,alpha,img2,0.25,0)\n",
    "        cv.imshow('Transition Effect ',output)\n",
    "        time.sleep(0.02)\n",
    "        if cv.waitKey(1) == 27:\n",
    "            skip = True\n",
    "            break       \n",
    "    if skip == True:\n",
    "        cv.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotate image by 45 degrees without cropping the sides of the image. (Hint: There are 2 strategies to tackle these problems). Use \"lena.jfif\" as the input image.\n",
    "* Use external libraries imutils.\n",
    "* Modify the transformation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('lena.jfif')\n",
    "rows, cols = img.shape[:2]\n",
    "M = cv.getRotationMatrix2D(((cols-1)/2.0, (rows-1)/2.0), 45, 1)\n",
    "\n",
    "img = imutils.resize(img,150,150)\n",
    "img = imutils.rotate_bound(img,45)\n",
    "\n",
    "dst = cv.warpAffine(img, M, (cols, rows))\n",
    "\n",
    "cv.imshow('rotated_image', dst)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the images with titles: \"flower.jfif\" and \"native-bee.png\". I want to put flower above an image. If I add two images, it will change color. If I blend it, I get a transparent effect. But I want it to be opaque. If it was a rectangular region, we could use the ROI as we did in the previous section. But flower is not a rectangular region. This is where bitwise operations, like AND, OR, NOT and XOR really come in handy. The associated functions are cv.bitwise_and(), cv.bitwise_or() and cv.bitwise_not(). You need to use cv.threshold function to segment the flower. Please refer to online documentation for more info. The result should resemble the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img1 = cv.imread('native-bee.png')\n",
    "img2 = cv.imread('flower.jfif')\n",
    "\n",
    "rows,cols,channels = img2.shape\n",
    "roi = img1[0:rows, 0:cols]\n",
    "\n",
    "\n",
    "img2gray = cv.cvtColor(img2,cv.COLOR_BGR2GRAY)\n",
    "ret, mask = cv.threshold(img2gray, 70, 255, cv.THRESH_BINARY)\n",
    "\n",
    "mask_inv = cv.bitwise_not(mask)\n",
    "\n",
    "img1_bg = cv.bitwise_or(roi,roi,mask = mask_inv)\n",
    "\n",
    "img2_fg = cv.bitwise_and(img2,img2,mask = mask)\n",
    "\n",
    "dst = cv.add(img1_bg,img2_fg)\n",
    "img1[0:rows, 0:cols ] = dst\n",
    "cv.imshow('res',img1)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5631220009749ff0edd890de05e99f7fd0c2132d8dfb7a25ad20f7f20483f41c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
